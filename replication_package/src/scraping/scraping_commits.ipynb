{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from token_manager import TokenManager\n",
    "from scraping_utils import get_paginated_data, parse_data, save_data_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../../data/pull_request\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token1 = os.getenv('TOKEN1')\n",
    "token2 = os.getenv('TOKEN2')\n",
    "\n",
    "tokens = [token1, token2]\n",
    "\n",
    "index_list_token = 0\n",
    "\n",
    "df = pd.read_csv(\"../../dataset/dataset_filtrado.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_manager = TokenManager(tokens)\n",
    "\n",
    "# Loop through each URL in the dataframe\n",
    "for url in df['URL']:\n",
    "\n",
    "    # Split the URL to extract the owner and repository name\n",
    "    parts = url.split('https://github.com/')[1].split('/')\n",
    "\n",
    "    owner = parts[0]\n",
    "    repo = parts[1]\n",
    "\n",
    "    # Construct the API URL to fetch commits\n",
    "    url_final = f\"https://api.github.com/repos/{owner}/{repo}/commits\"\n",
    "\n",
    "    print(url_final)\n",
    "\n",
    "    # Fetch data using the TokenManager for handling rate limits and authentication\n",
    "    data = get_paginated_data(url_final, token_manager)\n",
    "\n",
    "    # Define the filename to save the fetched data\n",
    "    filename = f\"../data/commits/commits_{owner}_{repo}.json\"\n",
    "\n",
    "    # Save the fetched data to a JSON file\n",
    "    save_data_to_json(data, filename)\n",
    "\n",
    "    print()  # Just to format the output for clarity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
