{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from token_manager import TokenManager\n",
    "from scraping_utils import get_paginated_data, parse_data, save_data_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../../data/pull_request' already exists.\n"
     ]
    }
   ],
   "source": [
    "directory = \"../../data/pull_request\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token1 = os.getenv('TOKEN1')\n",
    "token2 = os.getenv('TOKEN2')\n",
    "\n",
    "tokens = [token1, token2]\n",
    "\n",
    "index_list_token = 0\n",
    "\n",
    "df = pd.read_csv(\"../../dataset/dataset_filtrado.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TokenManager\n",
    "token_manager = TokenManager(tokens)\n",
    "\n",
    "# Read the filtered dataset\n",
    "df = pd.read_csv(\"../../dataset/dataset_filtrado.csv\", delimiter=';')\n",
    "\n",
    "# Iterate over the repository URLs in the dataset\n",
    "for url in df[\"URL\"]:\n",
    "    try:\n",
    "        # Parse the URL to get owner and repo\n",
    "        parts = url.split(\"https://github.com/\")[1].split(\"/\")\n",
    "        owner = parts[0]\n",
    "        repo = parts[1]\n",
    "    except IndexError:\n",
    "        print(f\"Invalid URL format: {url}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing repository: {owner}/{repo}\")\n",
    "\n",
    "    # Check if the issues data exists for the repository\n",
    "    issues_file = f\"../../data/issues/closed_issues_{owner}_{repo}.json\"\n",
    "    if os.path.exists(issues_file):\n",
    "        with open(issues_file, \"r\") as f:\n",
    "            try:\n",
    "                issues_data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Corrupted issues file '{issues_file}'. Skipping repository.\")\n",
    "                continue\n",
    "    else:\n",
    "        print(f\"Issues file for {owner}/{repo} not found.\")\n",
    "        continue  # Skip to next repository\n",
    "\n",
    "    # Check if pull request data exists\n",
    "    repo_filename = f\"{directory}/pull_files_{owner}_{repo}.json\"\n",
    "    if os.path.exists(repo_filename):\n",
    "        with open(repo_filename, \"r\") as f:\n",
    "            try:\n",
    "                existing_pr_data = json.load(f)\n",
    "                existing_pull_numbers = {pr[\"pull_number\"] for pr in existing_pr_data}\n",
    "                print(f\"Loaded {len(existing_pull_numbers)} existing PRs from '{repo_filename}'.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Corrupted JSON file '{repo_filename}'. Starting fresh.\")\n",
    "                existing_pr_data = []\n",
    "                existing_pull_numbers = set()\n",
    "    else:\n",
    "        existing_pr_data = []\n",
    "        existing_pull_numbers = set()\n",
    "        print(f\"No existing PR data found for {owner}/{repo}. Starting fresh.\")\n",
    "\n",
    "    # Iterate through the issues data and fetch pull request data\n",
    "    for issue in issues_data:\n",
    "        if \"pull_request\" in issue:\n",
    "            pull_number = issue[\"number\"]\n",
    "\n",
    "            if pull_number in existing_pull_numbers:\n",
    "                print(f\"PR #{pull_number} already scraped. Skipping.\")\n",
    "                continue \n",
    "\n",
    "            # Fetch pull request files data\n",
    "            api_url_files = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pull_number}/files\"\n",
    "            print(f\"Fetching files for pull request #{pull_number}...\")\n",
    "\n",
    "            pr_files_data = get_paginated_data(api_url_files, token_manager)\n",
    "\n",
    "            # Fetch main pull request data\n",
    "            api_url_main = f\"https://api.github.com/repos/{owner}/{repo}/pulls/{pull_number}\"\n",
    "            print(f\"Fetching main data for pull request #{pull_number}...\")\n",
    "            pr_main_data_list = get_paginated_data(api_url_main, token_manager)\n",
    "\n",
    "            if pr_files_data and pr_main_data_list:\n",
    "                pr_main_data = pr_main_data_list[0]  # Extract the dictionary from the list\n",
    "\n",
    "                additions = pr_main_data.get(\"additions\", 0)\n",
    "                deletions = pr_main_data.get(\"deletions\", 0)\n",
    "                changed_files = pr_main_data.get(\"changed_files\", 0)\n",
    "\n",
    "                # Prepare the pull request data entry\n",
    "                pr_entry = {\n",
    "                    \"pull_number\": pull_number,\n",
    "                    \"additions\": additions,\n",
    "                    \"deletions\": deletions,\n",
    "                    \"changed_files\": changed_files\n",
    "                }\n",
    "                print(pr_entry)\n",
    "\n",
    "                existing_pr_data.append(pr_entry)\n",
    "                existing_pull_numbers.add(pull_number)\n",
    "                print(f\"Data for pull request #{pull_number} fetched and added.\")\n",
    "\n",
    "                # Save the pull request data to a JSON file\n",
    "                save_data_to_json(existing_pr_data, repo_filename)\n",
    "                print(f\"PR #{pull_number} data saved to '{repo_filename}'.\")\n",
    "            else:\n",
    "                print(f\"No data fetched for pull request #{pull_number}.\")\n",
    "\n",
    "    print(f\"Completed processing for repository: {owner}/{repo}\")\n",
    "\n",
    "print(\"\\nAll data fetching completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
